{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:} glued_fig\n",
    "```\n",
    "\n",
    "# ✂️ Introduction to image segmentation\n",
    "\n",
    "This tutorial will give you a practical introduction to image segmentation. We'll aim to produce a segmentation mask that identifies objects of interest in an image. We will attempt to separate the objects from the background. Then, we'll see how to distinguish individual objects. Finally, we'll show how to measure properties (size, shape) of these objects.\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, make sure that you are executing this notebook in an environment with all the necessary packages installed. We'll import every function and library that we need in the cell below. We'll use these imports progressively in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.data\n",
    "from skimage.io import imshow\n",
    "from skimage.exposure import histogram\n",
    "from skimage.filters import sobel, threshold_otsu\n",
    "from skimage.measure import regionprops_table\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from myst_nb import glue  # To paste the figure output at the top of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image\n",
    "\n",
    "We will use the `coins` image from `skimage.data` as an example. This image shows several coins outlined against a darker background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.data.coins()\n",
    "\n",
    "print(f'Loaded image in an array of shape: {image.shape} and data type {image.dtype}')\n",
    "print(f'Intensity range: [{image.min()} - {image.max()}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our image looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the image histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, hist_centers = histogram(image)\n",
    "\n",
    "plt.plot(hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "First, we are going to attempt to segment the image by thresholding the graylevel intensities. For this, we select a threshold, and then apply it to the image. All the pixel intensity values above the selected threshold become 1, and the rest 0. This type of image array is known as a **binary mask**.\n",
    "\n",
    "```{mermaid}\n",
    "graph LR\n",
    "    A[Image] --> |Threshold| B[Binary mask]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a suitable binary mask, the challenge is to find a threshold value that works well for our image (if that is possible), that is, which accurately separates the foreground from the background pixels.\n",
    "\n",
    "In the cell below, we show you a way of creating an interactive threshold function using `ipywidgets`. Move the slider to see the effect on the segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(threshold):\n",
    "    binary_image = image > threshold\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(image, cmap='gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(binary_image, cmap='gray')\n",
    "    ax[1].set_title('Segmented Image')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "threshold_slider = ipywidgets.IntSlider(\n",
    "    value=threshold_otsu(image),\n",
    "    min=0,\n",
    "    max=255,\n",
    "    step=1,\n",
    "    description='Threshold:',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "ipywidgets.interactive(segment_image, threshold=threshold_slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{admonition} Automatic thresholding\n",
    "There are methods to automatically select intensity thresholds based on the image histogram. One of these methods is Otsu thresholding. You can try the following:\n",
    "\n",
    "```python\n",
    "from skimage.filters import threshold_otsu\n",
    "threshold = threshold_otsu(blobs)\n",
    "binary_blobs = blobs < threshold\n",
    "```\n",
    "However, this only selects a good guess for a threshold.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like simply thresholding the image leads either to missing significant parts of the coins, or to merging parts of the background with the coins. This is due to the inhomogeneous lighting of the image.\n",
    "\n",
    "Therefore, we'll try a more advanced segmentation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershed segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The watershed transform floods an image of elevation starting from markers, in order to determine the catchment basins of these markers. Watershed lines separate these catchment basins, and correspond to the desired segmentation.\n",
    "\n",
    "The choice of the elevation map is critical for good segmentation. Here, we use the Sobel operator for computing the amplitude of the intensity gradient in the original image (the edges):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = sobel(image)\n",
    "\n",
    "imshow(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first determine markers of the coins and the background. These markers are pixels that we can label unambiguously as either object or background. Here, the markers are found at the two extreme parts of the histogram of gray values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = np.zeros_like(image)\n",
    "markers[image < 30] = 1\n",
    "markers[image > 150] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compute the watershed transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = watershed(edges, markers)\n",
    "\n",
    "imshow(segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, the result is satisfying for all coins. Even if the markers for the background were not well distributed, the barriers in the elevation map were high enough for these markers to flood the entire background.\n",
    "\n",
    "To further improve the segmentation, we remove a few small holes using the `scipy.ndimage.binary_fill_holes()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = ndi.binary_fill_holes(segmentation - 1)\n",
    "\n",
    "imshow(segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our binary mask looks good. The next step is to distinguis the coins from each other, which we can do using an algorithm known as connected components labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected component labeling\n",
    "\n",
    "Conceptionally, label images are an extension of binary masks. In a label image, all pixels with value 0 correspond to background. Pixels with a value larger than 0 denote that the pixel belongs to an object and identifies that object with the given number. A pixel with value `1` belongs to  first object and pixels with value `2` belongs to a second object and so on. When objects are labeled subsequently, the maximum value in a label mask corresponds to the number of objects in the image.\n",
    "\n",
    "Let's label all the coins in our binary mask using the `ndi.label` function from Scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_segmentation, _ = ndi.label(segmentation)\n",
    "\n",
    "imshow(labeled_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice. Now, what if we want to measure some properties of our labeled objects, such as their size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring region properties\n",
    "\n",
    "After segmenting and labeling objects in an image, we can measure properties of these objects. To read out properties from regions, we use the [regionprops_table](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.regionprops) function from Scikit-image. We read the properties into a [Pandas DataFrame](https://biapol.github.io/Image-data-science-with-Python-and-Napari-EPFL2022/day4a_Tabular_Data/Tabular_Data.html), which is a common asset for data scientists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = regionprops_table(labeled_segmentation, intensity_image=image, properties=['label', 'area', 'centroid', 'bbox', 'eccentricity', 'intensity_mean'])\n",
    "\n",
    "df = pd.DataFrame(properties)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, we can study individual measurements or compute statistics on the whole dataset of detected objects. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the dataframe to disk conveniently, you could run `dataframe.to_csv(\"blobs_analysis.csv\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying a figure\n",
    "\n",
    "We use the `label2rgb` function from Scikit-image to display the segmentation overlaid on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rgb_composite = label2rgb(labeled_segmentation, image=image, bg_label=0)\n",
    "ax.imshow(rgb_composite)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Show the figure at the top of the notebook\n",
    "glue('glued_fig', fig, display=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
