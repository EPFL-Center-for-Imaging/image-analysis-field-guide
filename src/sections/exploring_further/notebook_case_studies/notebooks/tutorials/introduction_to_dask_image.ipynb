{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dask](../../../../../images/dask_image_lg.png)\n",
    "\n",
    "# Introduction to `Dask-image`\n",
    "---\n",
    "\n",
    "`Dask-image` is a `Dask` sub-package specialized for handling images. It supports many of the functions from `scipy.ndimage` for `Dask.arrays`\n",
    "\n",
    "* dask_image.imread\n",
    "* dask_image.ndfilters\n",
    "* dask_image.ndfourier\n",
    "* dask_image.ndinterp\n",
    "* dask_image.ndmeasure\n",
    "* dask_image.ndmorph\n",
    "\n",
    "In this notebook, we will use `Dask-image` for **lazy loading** a large image and **filtering** it.\n",
    "\n",
    "```{admonition} Acknowledgements\n",
    "This notebook was originally part of the 2023 workshop on [Accelerated large-scale image procesing in Python](https://github.com/EPFL-Center-for-Imaging/accel-large-image-proc-talk). We kindly acknowledge them for sharing their training material with us!\n",
    "```\n",
    "\n",
    "Tags: `Optimization`, `Tutorial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy loading with Dask_image.imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.array as da\n",
    "import dask_image.imread\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, zoom=False, titles=None, cmap=\"gray\", figsize=(20,10)):\n",
    "    zoom_mask = (slice(200, 800), slice(2320, 2750))\n",
    "    if cmap is None or isinstance(cmap, str):\n",
    "        cmap = [cmap, ] * len(images)\n",
    "    if titles is None or isinstance(titles, str):\n",
    "        titles = [titles, ] * len(images)\n",
    "    if zoom is None or isinstance(zoom, bool):\n",
    "        zoom = [zoom, ] * len(images)\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=figsize)\n",
    "    for ax, image in enumerate(images):\n",
    "        if zoom[ax]:\n",
    "            axs[ax].imshow(image[zoom_mask], cmap=cmap[ax])\n",
    "            axs[ax].set_title(titles[ax] + \"(zoom)\")\n",
    "        else:\n",
    "            axs[ax].imshow(image, cmap=cmap[ax])\n",
    "            axs[ax].set_title(titles[ax])\n",
    "        axs[ax].axis(\"off\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image -- this can take a bit (approx. 100Mb)\n",
    "url = \"https://stsci-opo.org/STScI-01EVSZWCFZVP2R5ZRV7HEZAGP6.tif\"\n",
    "\n",
    "data_path = Path(os.path.expanduser(\n",
    "    os.path.join(os.getenv(\"XDG_DATA_HOME\", \"~\"), \".field-guide\")\n",
    "))\n",
    "\n",
    "fname = 'hubble.tif'\n",
    "\n",
    "hubble_image = os.path.join(data_path, fname)\n",
    "urllib.request.urlretrieve(url, hubble_image)\n",
    "\n",
    "def chunk_image(image, chunk_size, output_dir):\n",
    "    shape = np.array(image.shape)\n",
    "    chunk = np.array(chunk_size)\n",
    "    chunk_counts = shape // chunk\n",
    "    for ids in itertools.product(*[np.arange(0, count) for count in chunk_counts]):\n",
    "        slices = tuple([slice(i * ch, (i + 1) * ch) for i, ch in zip(ids, chunk)])\n",
    "        string = \"-\".join([str(i).zfill(2) for i in ids])\n",
    "        skimage.io.imsave(\n",
    "            os.path.join(output_dir, f\"image-{string}.png\"), (image[slices] * 255).astype(np.uint8),\n",
    "            check_contrast=False\n",
    "        )\n",
    "\n",
    "# Crop/chunk size\n",
    "chunk_size = (256, 256, 3)\n",
    "\n",
    "# Save directory\n",
    "output_dir = os.path.join(data_path, \"hubble\")\n",
    "Path(os.path.join(data_path, \"hubble\")).mkdir(exist_ok=True)\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "img = img_as_float(imread(hubble_image))\n",
    "\n",
    "# Run cropping function\n",
    "chunk_image(img, chunk_size, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "filename_pattern = os.path.join(data_path, \"hubble\", \"image-*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiled_hubble_images = dask_image.imread.imread(filename_pattern)\n",
    "\n",
    "# Convert image to float\n",
    "tiled_hubble_images = tiled_hubble_images.astype(float) / 255.0\n",
    "tiled_hubble_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMINDER: Dask is lazy by default\n",
    "from sys import getsizeof\n",
    "print(f\"Size of `dask-image`: {getsizeof(tiled_hubble_images)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    [\n",
    "        tiled_hubble_images[0],\n",
    "        tiled_hubble_images[5],\n",
    "        tiled_hubble_images[10],\n",
    "        tiled_hubble_images[15],\n",
    "        tiled_hubble_images[20],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Applying your own custom function to images\n",
    "\n",
    "Next you'll want to do some image processing, and apply a function to your images.\n",
    "\n",
    "We'll use a very simple example: converting an RGB image to grayscale. \n",
    "\n",
    "To convert our image to grayscale, we'll use the equation to calculate luminance:\n",
    "\n",
    "```Y = 0.2125 R + 0.7154 G + 0.0721 B```\n",
    "\n",
    "We'll write the function for this equation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(rgb):\n",
    "    result = (rgb[..., 0] * 0.2125) + (rgb[..., 1] * 0.7154) + (rgb[..., 2] * 0.0721)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While NumPy attempts to optimize memory usage, **in-place operations** (where memory is reused) aren't always possible, especially when dealing with complex arithmetic operations. During the computation within the grayscale function, NumPy creates **temporary arrays**. When you perform operations like ```rgb[..., 0] * 0.2125```, it results in intermediate arrays being created in memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Temporary Arrays and In-Place Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this operation requires to have an extra copy of (one channel of) the input image in memory. Many operations require the creation, even temporarily, of array of the same size as the image. This can easily pose a bottleneck in our pipeline!\n",
    "\n",
    "Let's apply our custom function to the a **single chunk** of our image and visualize the computation graph.\n",
    "\n",
    "*TIP: Visualizing the computation graph isn't necessary but most of the time it's helpful to know what dask is doing under the hood, and it can also be very useful for debugging problems.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hubble_image = tiled_hubble_images[20].persist()\n",
    "\n",
    "plt.imshow(hubble_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_single_image = grayscale(hubble_image)\n",
    "print(result_single_image)\n",
    "result_single_image.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original image dimensions: \", hubble_image.shape)\n",
    "print(\"Processed image dimensions:\", result_single_image.shape)\n",
    "\n",
    "show_images(\n",
    "    [hubble_image, result_single_image],\n",
    "    titles=[\"Original image\", \"Processed image\"],\n",
    "    cmap=[None, \"gray\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarrassingly parallel problems\n",
    "\n",
    "The syntax is identical to apply a function to multiple images or Dask chunks. This is an example of an embarrassingly parallel problem, and we see that **Dask automatically creates a computation graph for each image chunk**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grayscale(tiled_hubble_images[:5].persist())\n",
    "print(result)\n",
    "result.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = grayscale(tiled_hubble_images)\n",
    "show_images(\n",
    "    [\n",
    "        result[0],\n",
    "        result[5],\n",
    "        result[10],\n",
    "        result[15],\n",
    "        result[20],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some Dask-image processing\n",
    "\n",
    "For illustration purposes, let's perform some [edge enhancement](https://www.wikiwand.com/en/Edge_enhancement) of our sky image.\n",
    "\n",
    "A very simple approach for edge enhancement is the following: \n",
    "\n",
    "$$\\hat{\\mathbf{I}} = (1-\\alpha) \\mathbf{I} + \\alpha \\vert  \\mathbf{I} - \\bar{\\mathbf{I}}_{\\sigma} \\vert $$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\hat{\\mathbf{I}}$ is the enhenced image,\n",
    "- $\\mathbf{I}$ is the original image, \n",
    "- $\\bar{\\mathbf{I}}_{\\sigma} $ is a smoothed version of $\\mathbf{I}$, with smoothing parameter $\\sigma$, and\n",
    "- $\\alpha \\in [0, 1]$ controls the level of enhancement. \n",
    "\n",
    "\n",
    "Let's complete the following function `edge_enhancement(image, sigma)` that uses `dask_image.ndfilters.gaussian_filter`:\n",
    "\n",
    "```python\n",
    "def edge_enhancement(image, sigma, alpha):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: Dask.array (2d)\n",
    "        Input image to enhance.\n",
    "    sigma: float\n",
    "        Smoothing parameter.\n",
    "    alpha: float [0, 1]\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_image: Dask.array (2d)\n",
    "        Edge enhanced image.\n",
    "    \"\"\"\n",
    "    \n",
    "    return NotImplementedError\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_image.ndfilters\n",
    "\n",
    "def edge_enhancement(image, sigma, alpha):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: Dask.array (2d)\n",
    "        Input image to enhance.\n",
    "    sigma: float\n",
    "        Smoothing parameter.\n",
    "    alpha: float [0, 1]\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_image: Dask.array (2d)\n",
    "        Edge enhanced image.\n",
    "    \"\"\"\n",
    "    assert sigma > 0\n",
    "    assert  0 <= alpha <= 1\n",
    "    smoothed_image = dask_image.ndfilters.gaussian_filter(image, sigma=sigma)\n",
    "    edge_enhanced_image = abs(image - smoothed_image)\n",
    "    edge_enhanced_image += alpha * image\n",
    "    return edge_enhanced_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join processed chunks\n",
    "Because our `edge_enhancement` function relies on a convolution (with a smoothing kernel), we need to concatenate the small image chunks together into the shape of the image. \n",
    "\n",
    "This is important when doing convolutions or other analysis that process the neighborhood of each pixel.\n",
    "\n",
    "This joined image will still be a **lazy array**, but each chunk will access the edge values of the neighboring chunks. \n",
    "\n",
    "*Note: We could have done this in the beginning too.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy Dataset for visualisation\n",
    "data = [result[20], result[21]]\n",
    "toy_combined_image = da.block(data).persist()\n",
    "toy_combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_enhanced_toy = edge_enhancement(toy_combined_image.persist(), \n",
    "                                     sigma=20, \n",
    "                                     alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to match the different parts of the task graph with the edge enhancement equation: \n",
    "\n",
    "$$\\hat{\\mathbf{I}} = (1-\\alpha) \\mathbf{I} + \\alpha \\vert  \\mathbf{I} - \\bar{\\mathbf{I}}_{\\sigma} \\vert $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edge_enhanced_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_enhanced_toy.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The toy dataset is useful to understand the task graph, and it can also be used to select good values for $\\sigma$ and $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.1, 0.5]\n",
    "sigmas = [1, 10, 20]\n",
    "\n",
    "for alpha, sigma in itertools.product(alphas, sigmas):\n",
    "    edge_enhanced_toy = edge_enhancement(toy_combined_image, \n",
    "                                     sigma=sigma, \n",
    "                                     alpha=alpha)\n",
    "    # Normalize between 0 and 1\n",
    "    edge_enhanced_toy -= edge_enhanced_toy.min()\n",
    "    edge_enhanced_toy /= edge_enhanced_toy.max()\n",
    "    \n",
    "    show_images(\n",
    "        [toy_combined_image, edge_enhanced_toy],\n",
    "        titles=[\"Original\", fr\"Enh ($\\sigma={sigma}$, $\\alpha={alpha}$)\"],\n",
    "        cmap=\"cubehelix\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: run full pipeline on RGB dataset, and save for later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhancing parameters\n",
    "sigma = 20\n",
    "alpha = 0.5\n",
    "\n",
    "# Full Dataset\n",
    "edge_enhanced_image = []\n",
    "combined_image = []\n",
    "# For each RGB\n",
    "for j in range(3):\n",
    "    # Join chunks to have access to neighborhoods\n",
    "    data = [\n",
    "        [img[..., j] for img in tiled_hubble_images[i * 28 : (i + 1) * 28]]\n",
    "        for i in range(24)\n",
    "    ]\n",
    "    combined_image.append(da.block(data))\n",
    "    \n",
    "    # Join chunks to have access to neighborhoods\n",
    "    edge_enh = edge_enhancement(combined_image[j], sigma=sigma, alpha=alpha)\n",
    "     # Normalize between 0 and 1\n",
    "    edge_enh -= edge_enh.min()\n",
    "    edge_enh /= edge_enh.max()\n",
    "    edge_enhanced_image.append(edge_enh)\n",
    "\n",
    "# Convert list to dask array\n",
    "edge_enhanced_image = da.dstack(edge_enhanced_image)\n",
    "combined_image = da.dstack(combined_image)\n",
    "edge_enhanced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    [\n",
    "        combined_image.blocks[0, 20],\n",
    "        edge_enhanced_image.blocks[0, 20],\n",
    "        abs((combined_image-edge_enhanced_image).blocks[0, 20]).clip(0,1),\n",
    "    ],\n",
    "    titles=[\"Original\", fr\"Edge Enhanced ($\\sigma={sigma}$, $\\alpha={alpha}$)\", \"Difference\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data\n",
    "To simplify data loading in the future, we store this large chunked-array as a [Zarr](https://zarr.dev/) file using the `dask.array.to_zarr` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_enhanced_image.to_zarr(os.path.join(\"imgs\", \"hubble_enh.zarr\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
